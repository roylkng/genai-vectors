*** Begin Patch
*** Update File: Cargo.toml
@@
 [dependencies]
+faiss = { version = "0.13.3", default-features = false, features = ["static"] }
 
*** Update File: src/model.rs
@@
 pub struct CreateIndex {
@@
     pub nbits: u32,
+    /// Optional default nprobe value used by the query service; if not provided the service will derive one.
+    pub default_nprobe: Option<u32>,
 }
*** End Patch
*** Begin Patch
*** Add File: src/faiss_utils.rs
+use anyhow::{Context, Result};
+use faiss::{index_factory, MetricType};
+
+/// Build an IVF-PQ index with the given hyperparameters and train it on `train_vectors`.
+///
+/// `dim` is the dimensionality of the vectors.
+/// `nlist` specifies the number of coarse centroids.
+/// `m` and `nbits` configure the product quantizer.
+/// `metric` should be "cosine" or "euclidean".
+pub fn build_ivfpq_index(
+    dim: usize,
+    nlist: u32,
+    m: u32,
+    nbits: u32,
+    metric: &str,
+    train_vectors: &[Vec<f32>],
+) -> Result<faiss::index_impl::BoxIndex> {
+    let metric = match metric {
+        "cosine" => MetricType::InnerProduct,
+        _ => MetricType::L2,
+    };
+    let factory = format!("IVF{},PQ{}x{}", nlist, m, nbits);
+    let mut index = index_factory(dim as i32, &factory, metric)
+        .context("Failed to create Faiss index")?;
+
+    // Flatten training vectors into a single contiguous buffer.
+    let mut training: Vec<f32> = Vec::with_capacity(dim * train_vectors.len());
+    for v in train_vectors {
+        training.extend_from_slice(v);
+    }
+    index.train(&training)?;
+    Ok(index)
+}
+
+/// Add vectors with explicit IDs to the index.
+/// Faiss expects the vectors as a contiguous slice and the IDs as i64.
+pub fn add_vectors(
+    index: &mut faiss::index_impl::BoxIndex,
+    vectors: &[Vec<f32>],
+    ids: &[i64],
+) -> Result<()> {
+    let dim = index.d() as usize;
+    let mut flat: Vec<f32> = Vec::with_capacity(dim * vectors.len());
+    for v in vectors {
+        flat.extend_from_slice(v);
+    }
+    index.add_with_ids(&flat, ids)?;
+    Ok(())
+}
+
+/// Save an index to the given file path.
+pub fn save_index(index: &faiss::index_impl::BoxIndex, path: &str) -> Result<()> {
+    faiss::io::write_index(index, path)?;
+    Ok(())
+}
+
+/// Load an index from the given file path.
+pub fn load_index(path: &str) -> Result<faiss::index_impl::BoxIndex> {
+    let index = faiss::io::read_index(path)?;
+    Ok(index)
+}
*** End Patch
*** Begin Patch
*** Update File: src/indexer.rs
@@ async fn process_index_slices(s3: &S3Client, index_name: &str, slice_paths: Vec<String>) -> Result<()> {
-    for shard_index in 0..num_shards {
-        let start_idx = shard_index * MAX_VECTORS_PER_SHARD;
-        let end_idx = std::cmp::min(start_idx + MAX_VECTORS_PER_SHARD, total_vectors);
-        
-        let shard_vectors = &all_vectors[start_idx..end_idx];
-        let shard_ids = &vector_ids[start_idx..end_idx];
-        let shard_metadata: HashMap<_, _> = shard_ids.iter()
-            .filter_map(|id| metadata.get(id).map(|meta| (id.clone(), meta.clone())))
-            .collect();
-
-        let shard_id = Uuid::new_v4().to_string();
-        let shard_info = create_shard(s3, index_name, &shard_id, shard_vectors, shard_ids, &shard_metadata, &config).await?;
-        
-        // 4. Update manifest for each shard
-        update_index_manifest(s3, index_name, shard_info, &config).await?;
-        
-        tracing::info!("Created shard {}/{} with {} vectors", 
-                       shard_index + 1, num_shards, end_idx - start_idx);
-    }
+    use crate::faiss_utils::{build_ivfpq_index, add_vectors, save_index};
+    use std::collections::hash_map::DefaultHasher;
+    use std::hash::{Hash, Hasher};
+    let timestamp = Utc::now().format("%Y%m%dT%H%M%S");
+
+    for shard_index in 0..num_shards {
+        let start_idx = shard_index * MAX_VECTORS_PER_SHARD;
+        let end_idx = std::cmp::min(start_idx + MAX_VECTORS_PER_SHARD, total_vectors);
+
+        let shard_vectors = &all_vectors[start_idx..end_idx];
+        let shard_ids_slice = &vector_ids[start_idx..end_idx];
+        let shard_metadata: HashMap<String, Value> = shard_ids_slice.iter()
+            .filter_map(|id| metadata.get(id).map(|meta| (id.clone(), meta.clone())))
+            .collect();
+
+        let shard_id = Uuid::new_v4().to_string();
+        // Build and train a Faiss IVF-PQ index for this shard.
+        let mut index = build_ivfpq_index(
+            config.dim as usize,
+            config.nlist,
+            config.m,
+            config.nbits,
+            &config.metric,
+            shard_vectors,
+        )?;
+        // Generate numeric IDs for Faiss from string IDs.
+        let mut faiss_ids: Vec<i64> = Vec::with_capacity(shard_ids_slice.len());
+        for id in shard_ids_slice {
+            let mut hasher = DefaultHasher::new();
+            id.hash(&mut hasher);
+            faiss_ids.push(hasher.finish() as i64);
+        }
+        add_vectors(&mut index, shard_vectors, &faiss_ids)?;
+
+        // Save index to a local temp file and upload.
+        let local_path = format!("/tmp/{}.faiss", shard_id);
+        save_index(&index, &local_path)?;
+        let index_object_path = format!("indexes/{}/shards/{}/index.faiss", index_name, shard_id);
+        s3.put_file(&index_object_path, &local_path).await?;
+
+        // Write mapping from hashed numeric ID to original ID.
+        let id_map: Vec<(i64, String)> = faiss_ids.iter().cloned().zip(shard_ids_slice.iter().cloned()).collect();
+        let id_map_data = serde_json::to_vec(&id_map)?;
+        let id_map_path = format!("indexes/{}/shards/{}/id_map.json", index_name, shard_id);
+        s3.put_object(&id_map_path, id_map_data.into()).await?;
+
+        // Persist metadata JSON.
+        let metadata_path = format!("indexes/{}/shards/{}/metadata.json", index_name, shard_id);
+        let meta_data = serde_json::to_vec(&shard_metadata)?;
+        s3.put_object(&metadata_path, meta_data.into()).await?;
+
+        // Construct shard info and update manifest.
+        let shard_info = ShardInfo {
+            shard_id: shard_id.clone(),
+            index_path: index_object_path,
+            metadata_path: metadata_path.clone(),
+            vector_count: shard_ids_slice.len(),
+            metric: config.metric.clone(),
+            created_at: timestamp.to_string(),
+        };
+        update_index_manifest(s3, index_name, shard_info, &config).await?;
+
+        tracing::info!("Created shard {}/{} with {} vectors", shard_index + 1, num_shards, end_idx - start_idx);
+    }
*** End Patch
*** Begin Patch
*** Update File: src/query.rs
@@ async fn search_shard(s3: &S3Client, req: &QueryRequest, shard: &ShardInfo) -> Result<Vec<SearchResult>> {
-    // 1. Load shard metadata (including vectors for simple brute force search)
-    let metadata = load_shard_metadata(s3, shard).await?;
-
-    // 2. Simple brute force vector search
-    let mut results = Vec::new();
-    let query_vector = &req.embedding;
-
-    for (i, id) in metadata.ids.iter().enumerate() {
-        if let Some(vector) = metadata.vectors.get(i) {
-            let score = match shard.metric.as_str() {
-                "cosine" => cosine_similarity(query_vector, vector),
-                "euclidean" => euclidean_similarity(query_vector, vector),
-                _ => cosine_similarity(query_vector, vector),
-            };
-
-            let vector_meta = metadata.metadata.get(id)
-                .cloned()
-                .unwrap_or_else(|| serde_json::json!({}));
-
-            results.push(SearchResult {
-                id: id.clone(),
-                score,
-                metadata: vector_meta,
-            });
-        }
-    }
-
-    // Sort by score and take top-k for this shard
-    results.sort_by(|a, b| b.score.partial_cmp(&a.score).unwrap_or(std::cmp::Ordering::Equal));
-    results.truncate(req.topk);
-
-    Ok(results)
+    use crate::faiss_utils::{load_index};
+    use std::collections::HashMap;
+
+    // Load metadata JSON for this shard.
+    let metadata_bytes = s3.get_object(&shard.metadata_path).await
+        .context("Failed to load shard metadata")?;
+    let metadata_map: HashMap<String, Value> = serde_json::from_slice(&metadata_bytes)
+        .context("Failed to parse shard metadata")?;
+
+    // Load ID map (numeric ID to original string ID).
+    let id_map_key = shard.index_path.replace("index.faiss", "id_map.json");
+    let id_map_bytes = s3.get_object(&id_map_key).await
+        .context("Failed to load id map")?;
+    let id_map: Vec<(i64, String)> = serde_json::from_slice(&id_map_bytes)
+        .context("Failed to parse id map")?;
+    let id_lookup: HashMap<i64, String> = id_map.into_iter().collect();
+
+    // Load Faiss index.
+    // Download index file to a temporary location.
+    let index_bytes = s3.get_object(&shard.index_path).await
+        .context("Failed to download index file")?;
+    let local_index_path = format!("/tmp/{}.faiss", shard.shard_id);
+    std::fs::write(&local_index_path, &index_bytes)?;
+    let mut index = load_index(&local_index_path)?;
+
+    // Set nprobe based on request or default. The CreateIndex.default_nprobe is stored in manifest.dim fields? Not yet.
+    if let Some(nprobe) = req.nprobe {
+        index.set_nprobe(nprobe as i32)?;
+    }
+
+    // Prepare query vector contiguous memory.
+    let query = &req.embedding;
+    // Faiss search expects multiple queries; we use 1.
+    let mut qbuf = query.clone();
+    let topk = req.topk as i64;
+    let (distances, labels) = index.search(&qbuf, topk)?;
+    let mut results: Vec<SearchResult> = Vec::new();
+    // distances and labels are 2D arrays; we have 1 query so index 0.
+    if let (Some(dist_row), Some(label_row)) = (distances.get(0), labels.get(0)) {
+        for (&dist, &label) in dist_row.iter().zip(label_row.iter()) {
+            if label < 0 { continue; }
+            if let Some(orig_id) = id_lookup.get(&label) {
+                // Filter by metadata if provided.
+                if let Some(filter) = &req.filter {
+                    // Only support simple equality filters like {"key":"value"}
+                    let mut matches = true;
+                    if let Some(obj) = filter.as_object() {
+                        if let Some(meta_value) = metadata_map.get(orig_id) {
+                            for (fk, fv) in obj {
+                                if meta_value.get(fk) != Some(fv) {
+                                    matches = false;
+                                    break;
+                                }
+                            }
+                        } else {
+                            matches = false;
+                        }
+                    }
+                    if !matches { continue; }
+                }
+                let meta = metadata_map.get(orig_id).cloned().unwrap_or_else(|| serde_json::json!({}));
+                let score = match shard.metric.as_str() {
+                    "cosine" => dist,       // inner-product gives similarity score
+                    _ => 1.0 / (1.0 + dist), // convert L2 distance to similarity
+                };
+                results.push(SearchResult {
+                    id: orig_id.clone(),
+                    score,
+                    metadata: meta,
+                });
+            }
+        }
+    }
+
+    // Already limited by topk; sort descending by score to be safe.
+    results.sort_by(|a, b| b.score.partial_cmp(&a.score).unwrap_or(std::cmp::Ordering::Equal));
+    Ok(results)
*** End Patch
*** Begin Patch
*** Update File: src/indexer.rs
@@
 use uuid::Uuid;
+use serde_json::Value;
*** End Patch
*** Begin Patch
*** Update File: src/lib.rs
@@
 pub mod query;
+pub mod faiss_utils;
*** End Patch
*** Begin Patch
*** Update File: src/indexer.rs
@@ async fn process_index_slices(s3: &S3Client, index_name: &str, slice_paths: Vec<String>) -> Result<()> {
-        // Save index to a local temp file and upload.
-        let local_path = format!("/tmp/{}.faiss", shard_id);
-        save_index(&index, &local_path)?;
-        let index_object_path = format!("indexes/{}/shards/{}/index.faiss", index_name, shard_id);
-        s3.put_file(&index_object_path, &local_path).await?;
+        // Save index to a local temp file and upload.
+        let local_path = format!("/tmp/{}.faiss", shard_id);
+        save_index(&index, &local_path)?;
+        let index_object_path = format!("indexes/{}/shards/{}/index.faiss", index_name, shard_id);
+        let idx_data = std::fs::read(&local_path)?;
+        s3.put_object(&index_object_path, idx_data.into()).await?;
*** End Patch
